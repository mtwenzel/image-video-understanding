{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_1_CNN_Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "FT00fFVb26XG",
        "mTRDkpaN26XZ"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtwenzel/image-video-understanding/blob/master/Session_1_CNN_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTDP7DB926WP"
      },
      "source": [
        "### This is a Jupyter notebook.  \n",
        "\n",
        "## General functions (of Jupyter environments)\n",
        "The most important keyboard shortcuts (cf. the \"Help\" menu) are\n",
        "* **cursor keys** to select cells\n",
        "* **Enter** to go from command mode to edit mode (for changing cell contents)\n",
        "  * (**Esc** would go back to command mode.)\n",
        "* **Shift+Enter** to *execute and advance* a cell\n",
        "  * While experimenting with different values in the same cell, **Ctrl+Enter** is also handy, which executes but does not advance the cursor.\n",
        "  * **ALT+Enter** will execute and advance to a **new** inserted cell.\n",
        "* There is an edit mode with a green bar to the left, and a execution/command mode with a blue bar.\n",
        "* In command mode, some keys have a function:\n",
        "    * `l`: toggle line numbers\n",
        "    * `a`: new cell above \n",
        "    * `b`: new cell below\n",
        "    * `h`: help / see more keyboard shortcuts\n",
        "    \n",
        "## Google Colab extra functions are provided:\n",
        "\n",
        "* Cells can **hide the code**. This is the case for the \"Imports\" cell below. Double-clicking still gets you to the code directly.\n",
        "* Cells can provide convenient **parameter interfaces**, like drop-down lists, sliders, and input fields. You will see this in the \"Initialize random data\" cell below. Again, double-clicking brings up the code.\n",
        "* Cells can be run automatically. For this, they have a special first line: ```#@title Cell title {run:\"auto\"}```. The \"Initialize Random Data\" cell is such a cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY6dUFRv26WR"
      },
      "source": [
        "# Image and Video Understanding -- Session 1 (Classification)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eki0pqq026WS"
      },
      "source": [
        "## 1. First Experiments with Random Data\n",
        "* Start by importing some required python modules that implement the layers we will use to build the network. \n",
        "* We also need a \"container\" to connect the layers: the \"Model\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7wllEz626WT",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "#@markdown To edit the imports, double-click on the cell\n",
        "\n",
        "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense, UpSampling2D, LocallyConnected2D, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_amAT5l26WW"
      },
      "source": [
        "### Create random data\n",
        "\n",
        "In these examples, we'll use artificial data first, and then switch to real data.\n",
        "\n",
        "Run the code in the following box, which will create a pair of input data `x_train` and corresponding output data `y_train` for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILE5IZO726WW",
        "cellView": "form"
      },
      "source": [
        "#@title Initialize random data {run:\"auto\"}\n",
        "#@markdown This cell needs to be executed only once. When you change parameters later, it auto-executes.\n",
        "#@markdown\n",
        "#@markdown ### Create random data sampled from uniform distribution.\n",
        "#@markdown\n",
        "#@markdown Set the desired number of instances\n",
        "NUM_INSTANCES = 100 #@param {type:'slider', min:0, max:10000, step:100}\n",
        "#@markdown Set the desired number of features (random from uniform distribution)\n",
        "NUM_FEATURES = 1000 #@param {type:'slider', min:0, max:10000, step:100}\n",
        "x_train = np.random.random((NUM_INSTANCES, NUM_FEATURES)) \n",
        "y_train = np.zeros((NUM_INSTANCES,)) # Label vector (initialized with 0s)\n",
        "y_train[:int(NUM_INSTANCES/2)] = 1 # set first half of vector to 1\n",
        "\n",
        "#@markdown The cell produces variable `x_train` and `y_train`. `x_train` contains the set number of instances, with the set number of features. `y_train` contains labels, with the first half `1`, and the second `0`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVi8E-9w26WY"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b398tpb26WZ"
      },
      "source": [
        "model = Sequential() # We choose a simple sequential model without branching\n",
        "model.add(InputLayer(input_shape = (NUM_FEATURES,)))\n",
        "#@markdown Play with the number of units (==neurons)\n",
        "model.add(Dense(units=256, name=\"Hidden\")) \n",
        "\n",
        "#@markdown Optionally increase the number of layers.\n",
        "#model.add(Dense(units=128))\n",
        "#model.add(Dense(units=64))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "model.summary()\n",
        "# @markdown If only interested in the number of parameters, use this:\n",
        "# @markdown `print(f\"Model parameters: {model.count_params()}\")`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8bU6j7r26Wb"
      },
      "source": [
        "### Training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1s0plRmN26Wc",
        "cellView": "form"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=10, epochs=100)\n",
        "#@markdown Clicking left to the output once will change the display mode from a scrollable field to a full display and back. Double-clicking it collapses it, so it is not so dominant.\n",
        "#@markdown In Google Colab, you can savely `x` the output with a click in the top left corner. This removes the printout, but not the cell results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Investigate the \"history\" object you created\n",
        "* Try out the following commands and inspect the variables.\n",
        "* Make use of tab completion, e.g. by typing `hidden_layer.<tab>`"
      ],
      "metadata": {
        "id": "3qhttNNYZ3OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = history.history['loss']\n",
        "weights = history.model.get_weights()\n",
        "hidden_layer = history.model.get_layer(\"Hidden\")\n",
        "for w in weights:\n",
        "    print(w.shape)"
      ],
      "metadata": {
        "id": "a0gUvPNGZsEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5RIUFuaaXz9"
      },
      "source": [
        "We want to display the loss function. Below, we display the learning success as measured by the loss.\n",
        "* `matplotlib` is a python package well suited plotting data and displaying images. Let's import it.\n",
        "* Then, plot the loss curve \"inline\" in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvYPXpRHaX0B"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRaH-vaK26Wt"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(18, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
        "ax.plot(history.history['loss'])\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optional task: use a validation set\n",
        "\n",
        "In addition to the training loss, we can also compute the loss on a validation set. For this purpose, we can define a designated validation set or use a fraction of the training set. Check the docs to find out, how to define validation data: https://keras.io/api/models/model_training_apis/#fit-method\n",
        "\n",
        "After retraining your model, try to find out how to read the validation loss from the history and plot it together with the training loss."
      ],
      "metadata": {
        "id": "7Cq2iOtYb7T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code goes here..."
      ],
      "metadata": {
        "id": "37yEp0Q3cOF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "#@markdown Expand code and set \"run_solution = True\" to see and run the solution.\n",
        "\n",
        "run_solution = False # set to True to run solution\n",
        "\n",
        "if run_solution:\n",
        "  # we added the validation_split\n",
        "  history = model.fit(x_train, y_train, batch_size=10, epochs=100, validation_split=0.2)\n",
        "                      \n",
        "  # alternative, when you have a separate set x_val and y_val\n",
        "  #history = model.fit(x_train, y_train, batch_size=10, epochs=100, validation_data=(x_val,y_val))\n",
        "\n",
        "  fig,ax = plt.subplots(figsize=(18, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
        "  ax.plot(history.history['loss'],label='Training')\n",
        "  # we access the validation loss\n",
        "  ax.plot(history.history['val_loss'],label='Validation')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Loss')\n",
        "  ax.grid()\n",
        "  ax.legend()\n",
        "  plt.show()\n",
        "else:\n",
        "  print('Solution is hidden, try for yourself first...')\n",
        "\n",
        "del run_solution\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qC80xFA5a5yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz8lrfL726We"
      },
      "source": [
        "### A remark on optimization\n",
        "* Optimizers like SGD, ADAM, ADAGrad ADADelta etc. are variants of Stochastic Gradient Descent (SGD).\n",
        "* SGD estimates the gradient for parameters based on a batch of examples.\n",
        "    * The larger the batch, the better the estimated gradiend approximates the gradient for the whole dataset.\n",
        "* It takes about 300 epochs to converge when creating 1000 instances.\n",
        "\n",
        "### Quiz: Interpreting the result\n",
        "* What can you observe regarding the loss?\n",
        "* Why is that possible?\n",
        "* Change the number of training instances to 1000. Assure that the classes are equally frequent again. What can you observe?\n",
        "* Be reminded that you have to re-create the model to reset the weights. To do this, execute the cell with the model definition (important is the `model.compile()` call)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZR1farX26Wh"
      },
      "source": [
        "## 2. Image Classification: _MNIST handwritten digits_\n",
        "\n",
        "### Read the data\n",
        "\n",
        "* We want to work on images: MNIST, which we import and load next.\n",
        "* You can import them from Keras with one line, because it is one of the standard datasets used for machine learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj5ic03p26Wi",
        "cellView": "form"
      },
      "source": [
        "#@title Import MNIST data\n",
        "#@markdown If you execute this cell, you will overwrite the data above. In addition, it gives you test data in `x_test` and `y_test`.\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reduce data by factor 10 / 20 for fast execution during course\n",
        "x_train = x_train[::10]\n",
        "y_train = y_train[::10]\n",
        "x_test = x_test[::20]\n",
        "y_test = y_test[::20]\n",
        "\n",
        "# verify resulting array shapes\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hftKUCa26Wk"
      },
      "source": [
        "### Inspecting the data\n",
        "\n",
        "Look at the shape of the `x_train` variable to understand how the data is organised.\n",
        "* You can see that the data has 60.000 examples, each of shape 28x28.\n",
        "* These are images... of size 28x28 pixels.\n",
        "* The corresponding output is just a long vector of corresponding labels in the range [0...9]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXSTdA6726Wl"
      },
      "source": [
        "# Inspect the shape of x_train\n",
        "print(x_train.shape, y_train.shape, y_train.min(), y_train.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syYfQPY626Wo"
      },
      "source": [
        "As we are dealing with *images* now, we want to display them.\n",
        "* `matplotlib` can also display images. We don't need to import it again.\n",
        "* Now, load and display one of the images \"inline\" in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckDwKNqc26Wq"
      },
      "source": [
        "# Look at an image\n",
        "plt.imshow(x_train[600], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NmZwqTQ26Wv"
      },
      "source": [
        "Also, we could be interested in the distribution of labels in our data:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n, bins, patches = plt.hist(y_train, facecolor='#2ab0ff', edgecolor='#e0e0e0', linewidth=0.5, alpha=0.7)\n",
        "n = n.astype('int') # it MUST be integer\n",
        "n_range=max(n)-min(n)\n",
        "# Good old loop. Choose colormap of your taste\n",
        "for i in range(len(patches)):\n",
        "    patches[i].set_facecolor(plt.cm.autumn_r((n[i]-min(n))/n_range))\n",
        "plt.grid(b=False, axis=\"x\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "76fq8Xbh8LD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD59O5wq26Wy"
      },
      "source": [
        "### Preparing the labels for a classification network\n",
        "We want to convert the numeric labels to so-called *\"one-hot vectors\"*.\n",
        "* One-hot means that the network does not directly output a number between 0 and 9 representing the digit.\n",
        "* Rather, we want a vector with 10 dimensions, in which only one entry is 1, all others 0, e.g. `[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]` to label a \"2\".\n",
        "* *Rationale:* The digits represent different categorical classes, and we want to penalize all confused digits the same; it is not \"better\" or \"closer\" if the network outputs 4.2 given an image depicting a \"6\" than if the output is 1.\n",
        "* In general, the one-hot encoding helps with classification problems and allows to let the neuron with maximal activation \"win\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muMO1Ar626Wz"
      },
      "source": [
        "num_labels = 10\n",
        "# Code to convert labels\n",
        "y_train_one_hot = (np.arange(num_labels) == y_train[:,np.newaxis]).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nxi5-3Q26W1"
      },
      "source": [
        "# Keras offers a convenience function to achieve the same:\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=num_labels)\n",
        "# Same for the testing data\n",
        "y_test_one_hot  = to_categorical(y_test, num_classes=num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huoaBC6D26W3"
      },
      "source": [
        "### Image classification with a simple neural network\n",
        "We now want to train the above network on this data. We have to adapt it to use inputs of a different shape, and to produce vector outputs. We have prepared this below:\n",
        "* Modified the parameter `input_shape=(...)` to adapt to the new data\n",
        "* Modified the number of dense units in the output layer to reflect the number of classes; 10 in the digits example\n",
        "* Modified the loss function to deal with multiple classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE0crVQE26W4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(28,28)))\n",
        "model.add(Flatten()) # Layer reshaping the 28x28 arrays into vectors of length 28*28=784\n",
        "model.add(Dense(units=256)) # Try higher or lower numbers of hidden units!\n",
        "# Try adding more layers!\n",
        "model.add(Dense(units=128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kBqoD79p26W6"
      },
      "source": [
        "# This experiments takes about 1 sec per epoch on an older MacBook Pro.\n",
        "history = model.fit(x_train, y_train_one_hot, batch_size=500, epochs=100) # In this example, you'll no longer want batches of size 10..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CutYDwpj26W9"
      },
      "source": [
        "### Evaluate the model on independent test data\n",
        "* The following cell executes the model on the test data\n",
        "* The result is a list of 10-vectors (recall the on-hot encoding), only this time there are also values between 0 and 1.\n",
        "* How can we compare these with the true labels in `y_test_one_hot`? There are many possible ways to evaluate classifiers; in general, you want to define some kind of error, usually based on differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UViKNdsj26W-"
      },
      "source": [
        "pred = model.predict(x_test)\n",
        "print(x_test.shape, pred.shape)\n",
        "print(pred[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A03cM7T26XC"
      },
      "source": [
        "The `argmax()` function may come in handy, which converts from the one-hot representation back to integer indices of the maximally activated classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HghimxdO26XD"
      },
      "source": [
        "pred.argmax(axis = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Let's have a look at some images together with their true label and predicted label. We can adapt the code from above...\n",
        "\n",
        "*Optional task*: Write a for loop to iterate over several images and plot only the images for a certain digit and/or with wrong classification - do you notice anything? (Maybe try to retrain your network for more epochs (e.g. 1000) before doing this.)"
      ],
      "metadata": {
        "id": "L37rp8RBgaE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0 # choose an image\n",
        "\n",
        "plt.imshow(x_test[k], cmap='gray')\n",
        "\n",
        "# your turn\n",
        "true_label = ... # To do\n",
        "predicted_label = ... # To do\n",
        "\n",
        "plt.title(f'True label: {true_label}\\nPredicted label: {predicted_label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QF5IyUdvgUM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "#@markdown Expand code and set \"run_solution = True\" to see and run the solution.\n",
        "\n",
        "run_solution = False # set to True to run solution\n",
        "\n",
        "if run_solution:\n",
        "\n",
        "  chosen_digit = 5 # choose a digit you want to check\n",
        "  max_examples = 3 # maximum number of examples to plot\n",
        "\n",
        "  counter = 0\n",
        "  for k in range(1000):\n",
        "    true_label = y_test[k]\n",
        "    predicted_label = pred[k].argmax(axis = -1)\n",
        "\n",
        "    # plot only wrong classifications\n",
        "    if true_label == chosen_digit and true_label != predicted_label:\n",
        "      counter += 1\n",
        "      plt.imshow(x_test[k], cmap='gray')\n",
        "      plt.title(f'True label: {true_label}\\nPredicted label: {predicted_label}')\n",
        "      plt.show()\n",
        "    if counter == max_examples:\n",
        "      break # max number of examples reached\n",
        "\n",
        "else:\n",
        "  print('Solution is hidden, try for yourself first...')\n",
        "\n",
        "del run_solution\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FN2vzER9g9Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGW5DKC26XF"
      },
      "source": [
        "## 3. Image classification with a simple convolutional neural network (CNN)\n",
        "For an introduction into convolutional layers, see course notes.\n",
        "\n",
        "### Weight sharing\n",
        "Exploring convolutions with and without weight sharing.\n",
        "* First, your input data now needs to have a \"channel\" dimension, as the convolutional filter result will be a multi-channel image.\n",
        "* Next, you will need to remove the 2D nature again to feed into dense layers. \n",
        "  * `Flatten()` does this for you.\n",
        "  * Train the network as before.\n",
        "  * What do you observe?\n",
        "\n",
        "Later, we'll explore how a convolutional layer without weight sharing affects the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT00fFVb26XG"
      },
      "source": [
        "#### With weight sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpzYN06B26XJ"
      },
      "source": [
        "convnet = Sequential()\n",
        "convnet.add(InputLayer(input_shape=(28,28,1)))\n",
        "convnet.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "convnet.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "convnet.add(MaxPool2D())\n",
        "convnet.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "convnet.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "convnet.add(MaxPool2D())\n",
        "convnet.add(Flatten())\n",
        "convnet.add(Dense(units=128))\n",
        "convnet.add(Dropout(0.5))\n",
        "convnet.add(Dense(units=10, activation='softmax'))\n",
        "convnet.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
        "print(\"convnet parameters: {0:,}\".format(convnet.count_params()))\n",
        "convnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Tcg3IqTK26XL"
      },
      "source": [
        "convnet_history = convnet.fit(x_train[...,np.newaxis], y_train_one_hot, batch_size=500, epochs=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNLigCrz26XO"
      },
      "source": [
        "**Exercise**: Plot the loss (history object, see above):\n",
        "\n",
        "*Optional task*: Go back to the first loss plot and define a function, which you can simply reuse here. If you plotted the validation loss before, do the same thing here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJDMn63L26XO"
      },
      "source": [
        "#plt.plot(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "#@markdown Expand code and set \"run_solution = True\" to see and run the solution.\n",
        "\n",
        "run_solution = False # set to True to run solution\n",
        "\n",
        "if run_solution:\n",
        "\n",
        "  # define the function\n",
        "  def plot_log(history):\n",
        "    fig,ax = plt.subplots(figsize=(18, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
        "    ax.plot(history.history['loss'],label='Training')\n",
        "    # we access the validation loss if available\n",
        "    if 'val_loss' in history.history:\n",
        "      ax.plot(history.history['val_loss'],label='Validation')\n",
        "      ax.legend()\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid()    \n",
        "    plt.show()\n",
        "\n",
        "  # apply the function\n",
        "  plot_log(convnet_history)\n",
        "\n",
        "else:\n",
        "  print('Solution is hidden, try for yourself first...')\n",
        "\n",
        "del run_solution\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xsnIbP6jkvLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0NTQY5G26XQ"
      },
      "source": [
        "If you have scikit-learn installed (try `conda install scikit-learn`), that offers utility methods for computing evaluation metrics such as a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unNbwnck26XQ"
      },
      "source": [
        "import sklearn.metrics\n",
        "pred = convnet.predict(x_test[...,np.newaxis])\n",
        "cm = sklearn.metrics.confusion_matrix(pred.argmax(axis = -1), y_test)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-a8xehI26XS"
      },
      "source": [
        "It's more intuitive to look at it as a heat map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWG4Typ426XT"
      },
      "source": [
        "plt.matshow(cm)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzp2Regj26XV"
      },
      "source": [
        "Side note: Numpy and Matplotlib are two important, central libraries for numeric computing with Python. In addition, there are also more advanced libraries such as Seaborn, which build upon the things introduced above and offer dedicated functions for complex graphics, such as a combined version of the above matrix + heatmap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGTlvLbD26XX"
      },
      "source": [
        "import seaborn as sns\n",
        "ax = sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTRDkpaN26XZ"
      },
      "source": [
        "#### Without weight sharing\n",
        "\n",
        "Now, let's try convolution without weight sharing.\n",
        "* Use `LocallyConnected2D` for this. \n",
        "* What do you observe? Try training the network.\n",
        "* Regard the number of parameters. Change the network, if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ev9hY7x26Xa"
      },
      "source": [
        "without_ws = Sequential()\n",
        "without_ws.add(InputLayer(input_shape=(28,28,1)))\n",
        "without_ws.add(LocallyConnected2D(32, kernel_size=(3,3)))\n",
        "#without_ws.add(LocallyConnected2D(32, kernel_size=(3,3)))\n",
        "without_ws.add(MaxPool2D())\n",
        "without_ws.add(LocallyConnected2D(32, kernel_size=(3,3)))\n",
        "#without_ws.add(LocallyConnected2D(32, kernel_size=(3,3)))\n",
        "without_ws.add(MaxPool2D())\n",
        "without_ws.add(Flatten())\n",
        "without_ws.add(Dense(units=128))\n",
        "without_ws.add(Dropout(0.5))\n",
        "without_ws.add(Dense(units=10, activation='softmax'))\n",
        "without_ws.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
        "print(\"without_ws parameters: {0:,}\".format(without_ws.count_params()))\n",
        "without_ws.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVt7amu026Xc"
      },
      "source": [
        "wws_history = without_ws.fit(np.reshape(x_train, x_train.shape+(1,)), y_train_one_hot, batch_size=10, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J5u-tE026Xm"
      },
      "source": [
        "plt.plot(wws_history.history['loss'])\n",
        "plt.show()\n",
        "import sklearn.metrics\n",
        "pred = without_ws.predict(x_test[...,np.newaxis])\n",
        "cm = sklearn.metrics.confusion_matrix(pred.argmax(axis = -1), y_test)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioGyPoNI26Xo"
      },
      "source": [
        "### From CNN to FCN\n",
        "* In the following, explore how a network with dense layers is equivalent to a properly configured fully-convolutional network\n",
        "* Flattening is replaced by a convolutional layer whose kernel spans the full size of the previous output. (Hint: use the model's `summary` function again to find the correct shape.)\n",
        "    * Replace the `Flatten` layer and subsequent `Dense` layers by `Conv2D` layers with appropriate kernel size.\n",
        "    * Note, that a `Flatten` layer is still required to convert into the output vector representation.\n",
        "* Convince yourself that the number of trainable parameters is indeed unchanged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQJ62yCUvIrJ"
      },
      "source": [
        "# Disable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iEY3Ym6e26Xo"
      },
      "source": [
        "# We call it FCN already, although it will be your task later to make it a true FCN by replacing the Dense layers. \n",
        "\n",
        "fcn = Sequential()\n",
        "h,w = x_train.shape[1:]\n",
        "fcn.add(InputLayer(input_shape=(h,w,1)))\n",
        "fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "fcn.add(MaxPool2D())\n",
        "fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "fcn.add(MaxPool2D())\n",
        "fcn.add(Flatten())\n",
        "fcn.add(Dense(128))\n",
        "fcn.add(Dropout(0.5))\n",
        "fcn.add(Dense(10, activation='softmax'))\n",
        "fcn.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
        "print(f\"fcn parameters: {fcn.count_params()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "#@markdown Expand code and set \"run_solution = True\" to see and run the solution.\n",
        "\n",
        "run_solution = False # set to True to run solution\n",
        "\n",
        "if run_solution:\n",
        "  fcn = Sequential()\n",
        "  h,w = x_train.shape[1:]\n",
        "  fcn.add(InputLayer(input_shape=(h,w,1)))\n",
        "  fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "  fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "  fcn.add(MaxPool2D())\n",
        "  fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "  fcn.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n",
        "  fcn.add(MaxPool2D())\n",
        "\n",
        "  # modified part\n",
        "  fcn.add(Conv2D(128, kernel_size=(7,7), padding='valid')) \n",
        "  fcn.add(Dropout(0.5))\n",
        "  fcn.add(Conv2D(10, kernel_size=(1,1)))\n",
        "\n",
        "  fcn.add(Flatten())\n",
        "  fcn.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
        "  print(\"fcn parameters: {0:,}\".format(fcn.count_params()))\n",
        "\n",
        "  fcn.summary()\n",
        "else:\n",
        "  print('Solution is hidden, try for yourself first...')\n",
        "\n",
        "del run_solution\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "txBkFFIVpvi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmLUezaY26Xq"
      },
      "source": [
        "fcn_history = fcn.fit(x_train[...,np.newaxis],\n",
        "                      y_train_one_hot,\n",
        "                      batch_size=500, epochs=10) #0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss once again (or reuse your function, if you implemented it earlier on.)"
      ],
      "metadata": {
        "id": "jD3cYxPjq-Oj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggWo2knS26Xs"
      },
      "source": [
        "plt.plot(fcn_history.history['loss'])\n",
        "plt.show()\n",
        "pred = fcn.predict(x_test[...,np.newaxis])\n",
        "cm = sklearn.metrics.confusion_matrix(pred.argmax(axis = -1), y_test)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32EC5_Dw26Xu"
      },
      "source": [
        "Exercise 1: \n",
        "\n",
        "Visualize this confusion matrix, compare "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tssSVlJSOK"
      },
      "source": [
        "# Room for code..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGh4PK9UI4in"
      },
      "source": [
        "Exercise 2: \n",
        "\n",
        "With a fully convolutional classifier, you can easily create a number detector. \n",
        "* How?\n",
        "* Can you show a proof of principle? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr_kE5dwJVa9"
      },
      "source": [
        "# Room for code..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}