{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtwenzel/image-video-understanding/blob/master/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J29FDh2JUNk_"
      },
      "source": [
        "# Self-Attention by Example\n",
        "\n",
        "Partially taken from https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a#8481"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HS7dexV7MphR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AoHRZd3SdJ0"
      },
      "source": [
        "## Create a tensor with input data\n",
        "\n",
        "In a real setting, this tensor would be the result of some data encoding step (when considering the first input to the first attention layer), or the result of the previous attention layer.\n",
        "\n",
        "If for example your input is text, and your word embeddings have 512 dimensions, each row in the tensor $x$ would have 512 entries, and the tensor would have as many rows as your sentence has words.\n",
        "\n",
        "For images (here described along the lines of the ViT), the number of rows in $x$ is the number of tiles the images get subdivided into ($16 \\times 16$ in ViT). The length of each line is the length of the embedding vector after transforming each tile with the patch encoder. [See the ViT publication for details](https://arxiv.org/abs/2010.11929)\n",
        "\n",
        "Note that there is the embedding size of the original data, but also the internal encoding size that will be determined by the shape of the K, Q, and V matrices."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adS8Vv9yZzQt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define data matrix {run:\"auto\"}\n",
        "#@markdown We create random(!) data of a given size. Set the number of tokens and the encoding/embedding length here.\n",
        "num_tokens = 5 #@param {type:\"slider\", min:\"1\", max:\"16\"}\n",
        "num_embedding_features = 9 #@param {type:\"slider\", min:\"1\", max:\"32\"}\n",
        "\n",
        "#@markdown Note that this enables us to show the process in the following, but that this is not describing a real task.\n",
        "\n",
        "x = torch.rand([num_tokens,num_embedding_features])\n",
        "x"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h_FPHgn8fTEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a047657c-622e-4cab-b434-4fbb4260d971"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4156, 0.6078, 0.1973, 0.5567, 0.1540, 0.7106, 0.9954, 0.1008, 0.9984],\n",
              "        [0.7734, 0.6256, 0.8363, 0.4454, 0.1385, 0.8334, 0.2375, 0.0403, 0.6473],\n",
              "        [0.7346, 0.9989, 0.2948, 0.7467, 0.8937, 0.2542, 0.0730, 0.7989, 0.5252],\n",
              "        [0.3206, 0.7222, 0.8778, 0.0395, 0.7015, 0.4138, 0.0287, 0.7658, 0.6030],\n",
              "        [0.4557, 0.6276, 0.2553, 0.7938, 0.0965, 0.5237, 0.0223, 0.5436, 0.5699]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-E_fY_cdNJwO",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b61893-7475-4a73-a106-a71f2b6376c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3712, 0.9761, 0.3577, 0.7554, 0.5756, 0.0036, 0.9795, 0.0935, 0.6094],\n",
              "        [0.7697, 0.3248, 0.0267, 0.2948, 0.1602, 0.4951, 0.2817, 0.4947, 0.5962]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#@title Define second data matrix for cross attention {run:\"auto\"}\n",
        "#@markdown To demonstrate cross attention with smaller attention matrix analogous to Perceiver or DETR, create a \"learned queries\" matrix $x_2$\n",
        "#@markdown For consistency, you can only adjust the number of tokens. The embedding dimension is kept from above.\n",
        "num_ca_tokens = 2 #@param {type:\"slider\", min:\"1\", max:\"10\"}\n",
        "\n",
        "x2 = torch.rand([num_ca_tokens, num_embedding_features])\n",
        "x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmV9pihNSumD"
      },
      "source": [
        "## Create a set of weight tensors. \n",
        "We are looking at single-head attention only for the moment. For multi-head attention, each weight matrix would be replicated (with independent weights) for each head. You will see this in the second half of the notebook.\n",
        "\n",
        "Each weight tensor has to have as many rows as the tokens have dimensions. Our input vectors have ```num_embedding_features``` dimensions. Let's create random weight matrices of the according size. You are free to select the other dimension, which will then be the internal embedding dimension.\n",
        "\n",
        "Observe how the size of these matrices does not depend on the number of tokens anymore.\n",
        "\n",
        "Note that this will result in a matrix output after the attention mechanism, instead of a single token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ZSd8O7IANOK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b2f84e-fc7e-438d-b93a-34a9bc69f405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized random tensors w_key (9, 7), w_query (9, 7), w_value (9, 7).\n"
          ]
        }
      ],
      "source": [
        "#@title Get K, Q, V transform matrices {run:\"auto\"}\n",
        "\n",
        "internal_embedding_dimensions = 7 #@param {type:\"slider\", min:\"1\", max:\"32\"}\n",
        "\n",
        "w_key = torch.rand([num_embedding_features,internal_embedding_dimensions])\n",
        "w_query = torch.rand([num_embedding_features,internal_embedding_dimensions])\n",
        "w_value = torch.rand([num_embedding_features,internal_embedding_dimensions])\n",
        "\n",
        "print(f'Initialized random tensors w_key {tuple(w_key.shape)}, w_query {tuple(w_query.shape)}, w_value {tuple(w_value.shape)}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqLOpyeETMBN"
      },
      "source": [
        "## K, Q, and V\n",
        "\n",
        "The actual keys, querys and values are the result of the multiplication of input tensor with weight tensors.\n",
        "\n",
        "Their dimension is:\n",
        "* each row has as many entries as the weight tensors (three in our setup)\n",
        "* the number of rows equals the number of input tokens (five in our setup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TXXZUtWWNSjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e983e9c6-be09-4f6e-fa1d-20f6c938beea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: tensor([[2.0902, 2.0839, 3.4129, 2.2058, 2.1916, 2.3763, 2.8780],\n",
            "        [1.6638, 1.7538, 3.5822, 1.8338, 1.8393, 2.7197, 2.7774],\n",
            "        [1.7982, 2.2932, 3.9255, 2.1781, 2.2116, 2.3433, 2.6364],\n",
            "        [1.9205, 1.9819, 3.3125, 1.4930, 2.2447, 2.1660, 2.1253],\n",
            "        [1.2691, 1.4000, 3.1406, 1.7010, 1.5117, 2.2384, 2.0970]])\n",
            "Queries: tensor([[3.6041, 3.3453, 2.2808, 2.1118, 1.6603, 2.2617, 2.7830],\n",
            "        [3.7238, 2.7367, 2.5857, 1.9146, 1.7753, 1.9686, 2.3191],\n",
            "        [3.7820, 3.3642, 2.6344, 2.4534, 2.9739, 3.0887, 3.0315],\n",
            "        [3.1552, 2.8429, 2.2283, 2.1906, 2.3385, 2.1164, 2.4907],\n",
            "        [2.7700, 2.4532, 1.8175, 1.7777, 1.5463, 2.0947, 2.1202]])\n",
            "Cross-attention Queries: tensor([[3.5115, 3.1653, 2.1434, 2.2128, 2.3216, 2.6422, 2.3595],\n",
            "        [2.5118, 2.4742, 1.8477, 1.4342, 1.5480, 1.8219, 2.2171]])\n",
            "Values: tensor([[2.1637, 2.1600, 2.5970, 1.6369, 1.6383, 2.0975, 2.8445],\n",
            "        [1.9769, 1.8367, 2.8011, 2.0245, 1.7374, 1.7549, 2.1575],\n",
            "        [2.2176, 2.5780, 3.8284, 2.8816, 2.0878, 1.9463, 2.5527],\n",
            "        [2.2855, 2.0169, 3.2748, 2.2827, 2.0756, 1.5940, 2.3809],\n",
            "        [1.4337, 1.7439, 2.6349, 2.1364, 1.7177, 1.5444, 1.6235]])\n"
          ]
        }
      ],
      "source": [
        "keys = x @ w_key\n",
        "querys = x @ w_query\n",
        "values = x @ w_value\n",
        "\n",
        "# This would be the cross attention with a potentially different number of tokens\n",
        "xattn_q = x2 @ w_query\n",
        "\n",
        "\n",
        "print(\"Keys:\",keys)\n",
        "print(\"Queries:\",querys)\n",
        "print(\"Cross-attention Queries:\",xattn_q)\n",
        "print(\"Values:\",values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNK5GEeBTfKC"
      },
      "source": [
        "## Softmax Attention\n",
        "\n",
        "The size of the square attention matrix equals the number of input tokens in both dimensions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OoT9rEVZNVIN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "325e8d37-8c33-4da6-86f1-5a45af4facc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4800, 0.0200, 0.5000, 0.0000, 0.0000],\n",
            "        [0.4500, 0.0200, 0.5300, 0.0000, 0.0000],\n",
            "        [0.4700, 0.0100, 0.5200, 0.0000, 0.0000],\n",
            "        [0.4600, 0.0200, 0.5200, 0.0000, 0.0000],\n",
            "        [0.4700, 0.0400, 0.4800, 0.0100, 0.0000]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f958b3ddd90>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "attn_scores = querys @ keys.T\n",
        "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
        "\n",
        "# For readability, round the scores to a definable number of decimal places\n",
        "print(attn_scores_softmax.round(decimals = 2))\n",
        "\n",
        "# Plot self attention matrix\n",
        "sns.heatmap(attn_scores_softmax.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do the same for \"cross attention\""
      ],
      "metadata": {
        "id": "purX4lQ8XkJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xattn_scores = xattn_q @ keys.T\n",
        "xattn_scores_softmax = softmax(xattn_scores, dim=-1)\n",
        "\n",
        "# For readability, round the scores to a definable number of decimal places\n",
        "print(xattn_scores_softmax.round(decimals = 2))\n",
        "\n",
        "# Plot self attention matrix\n",
        "sns.heatmap(xattn_scores_softmax.numpy(), square = True)"
      ],
      "metadata": {
        "id": "hM8FSWsWXc_y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "34f433d8-42e7-4843-845f-1c805c1dd3f8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4700, 0.0200, 0.5000, 0.0000, 0.0000],\n",
            "        [0.4400, 0.0500, 0.5000, 0.0100, 0.0000]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f958b36b370>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUABFsoQTyAV"
      },
      "source": [
        "## Multiply softmax attention with V to obtain the result\n",
        "\n",
        "In a transformer, dense layers would follow that can \n",
        "* reduce a multi-head attention result\n",
        "* enforce correct dimensionality to use output in next input.\n",
        "\n",
        "We will see this after the following experiment with multi-head attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uKW44_0GNjAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a138da44-3857-406d-9b20-c3b714e69d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.1870, 2.3615, 3.2178, 2.2681, 1.8659, 2.0135, 2.6832],\n",
            "        [2.1883, 2.3720, 3.2536, 2.3047, 1.8794, 2.0076, 2.6726],\n",
            "        [2.1892, 2.3719, 3.2396, 2.2889, 1.8735, 2.0135, 2.6826],\n",
            "        [2.1882, 2.3697, 3.2434, 2.2940, 1.8755, 2.0098, 2.6766],\n",
            "        [2.1826, 2.3470, 3.2062, 2.2602, 1.8632, 2.0058, 2.6703]])\n"
          ]
        }
      ],
      "source": [
        "weighted_values = values[:,None] * attn_scores_softmax.T[:,:,None]\n",
        "outputs = weighted_values.sum(dim=0)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention"
      ],
      "metadata": {
        "id": "_nVYTdZwwLvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define number of heads, and create according random weight matrices K, Q, V {run:\"auto\"}\n",
        "#@markdown The only required change is to stack multiple K, Q, V. \n",
        "\n",
        "num_heads = 4 #@param {type:\"slider\", min:\"2\", max:\"10\"}\n",
        "\n",
        "w_key = torch.rand([num_heads, num_embedding_features,internal_embedding_dimensions])\n",
        "w_query = torch.rand([num_heads,num_embedding_features,internal_embedding_dimensions])\n",
        "w_value = torch.rand([num_heads,num_embedding_features,internal_embedding_dimensions])\n",
        "print(f'Initialized new random tensors w_key {tuple(w_key.shape)}, w_query {tuple(w_query.shape)}, w_value {tuple(w_value.shape)}.')"
      ],
      "metadata": {
        "id": "uKbJPwXkOoPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f203b78a-edcb-41b5-e3ac-5bcae44f6851"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized new random tensors w_key (4, 9, 7), w_query (4, 9, 7), w_value (4, 9, 7).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cNyAD9WWZYfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af90ecd-374f-4162-a90c-f730add7964b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.2762, 2.2917, 1.2495, 2.7910, 1.9137, 2.3799, 3.2208],\n",
            "         [2.6289, 2.0382, 1.2609, 2.2294, 1.9033, 2.8278, 2.5340],\n",
            "         [3.2353, 2.5829, 1.7876, 3.2496, 2.8888, 3.2688, 3.4099],\n",
            "         [2.9499, 2.0941, 1.6858, 2.6115, 2.5351, 2.8167, 2.8942],\n",
            "         [2.1926, 1.8038, 1.0624, 2.2006, 1.8991, 2.5380, 2.4275]],\n",
            "\n",
            "        [[1.7812, 3.0296, 2.3910, 2.0282, 2.7318, 2.7690, 1.8514],\n",
            "         [1.7456, 2.9088, 2.3056, 2.7378, 2.4049, 2.6458, 1.5828],\n",
            "         [2.0844, 3.4808, 2.5568, 2.6643, 3.2205, 2.7003, 2.6002],\n",
            "         [1.8855, 2.5050, 2.2587, 2.5920, 3.1021, 2.2466, 1.7921],\n",
            "         [1.4625, 2.8753, 1.9147, 1.8097, 1.9417, 2.2449, 1.7453]],\n",
            "\n",
            "        [[2.8959, 2.2872, 2.9080, 3.2866, 3.3510, 2.1515, 2.2184],\n",
            "         [2.4278, 1.9565, 3.4100, 2.7269, 2.8639, 1.9928, 2.3566],\n",
            "         [3.2440, 2.2790, 3.4319, 3.4115, 2.8352, 2.4098, 2.7259],\n",
            "         [2.2699, 1.7876, 2.7940, 2.5822, 2.5220, 1.7528, 2.2614],\n",
            "         [2.1201, 1.8633, 2.8213, 2.6513, 2.1960, 1.8855, 2.3285]],\n",
            "\n",
            "        [[2.3191, 2.6042, 2.3211, 1.8075, 1.5636, 1.9731, 1.3237],\n",
            "         [1.9170, 2.5838, 1.7958, 1.6324, 2.0472, 2.3854, 1.5591],\n",
            "         [3.1208, 2.5948, 2.5340, 2.1267, 2.1337, 3.4155, 2.6565],\n",
            "         [2.1003, 2.2760, 1.6893, 1.4688, 1.5818, 3.1858, 2.2074],\n",
            "         [2.2392, 1.9596, 1.9306, 1.8264, 1.6190, 2.1203, 1.5506]]])\n"
          ]
        }
      ],
      "source": [
        "keys = x @ w_key\n",
        "querys = x @ w_query\n",
        "\n",
        "xattn_q = x2 @ w_query\n",
        "\n",
        "values = x @ w_value\n",
        "\n",
        "print(keys)\n",
        "#print(querys)\n",
        "#print(xattn_q)\n",
        "#print(values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = querys @ keys.mT \n",
        "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
        "\n",
        "def show_multihead_attention(attn_scores_softmax, column_count = 2):\n",
        "  '''Plot self attention matrices for different heads'''\n",
        "  row_count = num_heads // column_count\n",
        "  f, axx = plt.subplots(row_count, column_count,\n",
        "                        sharex = True, sharey = True,\n",
        "                        figsize = (column_count * 2, row_count * 2))\n",
        "  for ax, t in zip(axx.ravel(), attn_scores_softmax.numpy()):\n",
        "    sns.heatmap(t, ax = ax, square = True)\n",
        "\n",
        "show_multihead_attention(attn_scores_softmax)"
      ],
      "metadata": {
        "id": "bKW_rBOtZe4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "9349afbb-d4a9-4f7c-ee4f-6776fe49a139"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 8 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAREAAADwCAYAAAAn+1AdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZFUlEQVR4nO3de6xdZZnH8e/vlJZbtdTpyEBxuHgZ8TZtbMCEqKgIdTSVRM1U4ygG7WQi4mWSEWNGFKNpvPuHf9AQMpqZgCNjFBVliFCGDKKFESkXjdB44aggVkWkcvba+5k/9jq4um9r7XXZez2nzydZ4Zy999r7Pf0tnnfd9vvKzAghhLIW5t2AEIJvUURCCJVEEQkhVBJFJIRQSRSREEIlUURCCJUcNu8GhHI6D+0buja/esMpmkdbQnM85BxFxKtuZ94tCLPgIOcoIk5ZN5l3E8IMeMg5iohXncfm3YIwCw5yjiLilYMeKtTAQc5RRJyyZGneTQgz4CHnKCJeOdjNDTVwkHMUEa8c7OaGGjjIOYqIU5a0v4cK1XnIufEictiajXMdsOTAL26qtP6Rx7+wppaUlywtDt9c1LL7ByLn6jzkPErsiXjl4IRbqIGDnKOIeJW0/1g51MBBzlFEnPJwrByq85BzFBGvOu3fzQ01cJBzFBGvHFz6CzVwkHNuEZH0TODVwMb0oUXgajO7p8mGhRwOeqhQAwc5TxyUSNJ7gSsBAd9LFwFXSLqo+eaFsbrJ8BJWHgc55+2JnA8828wOulgt6VPAXcDOUStJ2gHsANCqdSwsHF1DU8NBWtBDRc4z0IKc8+QVkR5wPPDTgcePS58bycx2Abtg/jchrVid+d+EFDnPQAtyzpNXRN4FfFvSj4Gfp4/9NfA04IImGxZytHC3NjTAQc4Ti4iZfUvSM4DTOPjE6h4z6zbduDCBgx4q1MBBzrlXZ8ysB9wyg7aEKVi3XA2XtBX4LLAKuMzMdg48/2ngJemvRwFPNrNj0ue6wN70uZ+Z2bZSjQiFecg57hPxqkQPJWkV8Dng5cD9wB5JV5vZ3cuvMbN3Z17/DmBz5i0OmNmm0m0O03OQc8w741WnM7zkOw2418z2mdkS/cv3r57w+tcDV9TQ2lCWg5yjiHiVdIeXfBv58wly6PdSG0e9UNKJwMnA9ZmHj5B0q6RbJJ1btulhCg5yjsMZp2xEj5S9byO1K70MW8Z24KqBE+gnmtmipFOA6yXtNbP7Sr5/vXor8zy/h5yjiHg14oRb9r6NMRaBp2R+PyF9bJTtwNsH3n8x/e8+SbvpH0e3o4isVA5yjsMZr5aS4SXfHuDpkk6WtIb+BnT14IvS70utB76TeWy9pMPTnzcAZwB3D64bauYg59gTcWrUbm7uOmaJpAuAa+lf+rvczO6SdAlwq5ktb2jbgSvNLHsX6qnApZJ69Dufndmz/aEZHnKOIuJVMvZbBxOZ2TXANQOPfWDg9w+OWO9m4LmlPjSU5yDnKCJOWaf9t0OH6jzkHEXEq2KX+oJ3DnKOIuKUddq/cYXqPORc+uqMpLdMeG5HerPKrb3eH8t+RJgk6Q0vMxY5z0ALcs5T5RLvh8Y9YWa7zGyLmW2JgWqaYUu9oWXmbYicG9eGnPNMPJyRdMe4p4Bj629OKKqNG1Oon4ec886JHAucA/x24HEBNzfSolCIJTGQ2KHAQ855ReTrwFozu33wifR22DAnvaX2b1yhOg85541sdv6E595Qf3NCUdb+2wdCDTzkHJd4neq1fxDwUAMPOUcRcarX0bybEGbAQ85RRJzqJe3fuGZqYdW8W9AIDzlHEXGq24lRHA4FHnKOIuJUr9v+HipU5yHnKCJOeeihQnUeco4i4lSStH/jCtV5yLn9LQwj9boLQ0sRkrZK+pGkeyVdNOL58yT9WtLt6fLWzHNvlvTjdHlzjX9OGMNDzrEn4lSZHqrIpEapL5rZBQPrPgm4GNgCGHBbuu7gVyJCjTzknNtCSc+U9DJJawce31roLwqN6PU0tBQw7aRGWecA15nZ/nSDug6IbaBhHnKeWEQkXQh8FXgHcKekbEM+WrBRoQFJd2FoKaDopEavkXSHpKskLU89UHhCpFAfDznntehtwPPN7FzgTOBfJb0zfW5sSYzBaprX6a4aWrL/7umyI/+dhnwNOMnMnke/F/r8hNeeHjk3qyU5T5R3TmTBzB4BMLOfSDoTuCqdem9sEclOrnPYmo3t/xqiQ10b/uevY1IjM/tN5tfLgI9l1j1zYN0vm9kVEDk3pSU5757Uxrw9kQckPT47eFpQXgVsIKYPmKvEFoaWAnInNZJ0XObXbcA96c/XAmenkxutB85OHwsN8pBz3p7Im4CDvoxsZgnwJkmX5v0loTnJiB4qT8FJjS6UtI1+7vuB89J190v6MP0NFOASM9tf/S8Jk3jIWQdPflW/ee/mHvjFTZXWP/L4F9bUkvKSpcWhLem/j90+9O969gNXzu0e6ci5Og85jxL3iTjlYKyaUAMPOUcRcaqjuNn4UOAh5ygiTnXUqj3a8ZfqCqp8LNSdfuJrD9qW8yhRRJxq/7xooQ4eco4i4pSHHipU5yHnKCJOORg1L9TAQ85RRJxyMH5vqIGHnKOIOOVh4wrVecg5iohTHk64heo85JxbRCSdBpiZ7ZH0LPpjC/zQzK5pvHVhrCUHPVSozkPOE4uIpIuBVwCHSboOOB24AbhI0mYz+8gM2hhGcDAIeKiBh5zz9kReC2wCDgd+BZxgZg9L+gTwXWBkEUnHN9gBoFXrWFg4ur4WBwA61W/Pqiyb80Lk3Ig25Jwnr4gkZtYFHpV0n5k9DGBmByT1xq0U44k0rw33Z2ZzXh05N6INOefJKyJLko4ys0eB5y8/KGkdMLaIhOYliv9nDwUecs4rIi8ys8cAzCxbNFYDMWXAHHnYzQ3Vech54lcElwvIiMcfMrO9zTQpFNEdsRRRYD6S90i6Ox3A99vpUJjLz3Uz85RcPbhuqJ+HnOM+EafK9FAF5yP5PrDFzB6V9E/0x978+/S5A2a2iTAzHnJu/2AFYaQuNrQUkDsfiZndkJ4DA7iF/kC9YU485BxFJEfVYfea0qE3tBQw7Zwi5wPfzPx+RDpFwS2Szp2+1e2liktTPOQchzM52jD25iijdnOz922kdqWXYacm6Y30p1J8cebhE81sUdIpwPWS9prZfWXePxTjIecoIk6N2q2tYz4SAElnAe8HXpw9uW5mi+l/90naDWwGoog0yEPOcTjjVMd6Q0sBReYj2QxcCmwzswczj6+XdHj68wbgDGBwguhQMw85x56IUwVPsB2k4HwkHwfWAl9Sf1Stn5nZNuBU4NL0TuUFYOeIWeZDzTzkHEXEqYIn2Iak376+ZuCxD2R+PmvMejcTsx7OnIeco4g4VXC3NjjnIeepz4lI+kITDQnT6dIbWsLK4yHnvPFEBm95FfASSccApMdQYQ4SBz1UqM5DznmHMyfQPzN7Gf35hUT/mvInJ60U44k0r9uCjSvGE2leG3LOk3c4swW4jf615N+b2W7699XfaGY3jlvJzHaZ2RYz2xIbVjM61h1aZi1ybl4bcs4zcU8k/fr/pyV9Kf3vA3nrhNkoe9Y++OIh50IFwczuB14n6ZXAw802KRThYTc3VOch56n2KszsG8A3GmpLmELSwt3aUD8POcehiVMeeqhQnYeco4g45aGHCtV5yDmKiFOdXvs3rlCdh5wbLyLJ0uLEMVsk7Sg7FkJd7zFp/WRp6BvUM/38cdq2m9tpOOemt5NO5FxaG4YC2JH/ksbfw936iSVDS8vN+9+4DW1YkTnH4YxTHnqoUJ2HnKOIOJU4OFYO1XnIuQ1FpNJxbk3v4W59Dz3UgHn/G7ehDSsyZ5m1f4atMGz92qcNBffbR+51MId8mIaHnNuwJxJK8HDpL1TnIecoIk552M0N1XnIOYqIU10HPVSozkPOcU4khFBJG242CyE4FkUkhFBJFJEQQiVRREIIlUQRCSFUEkUkhFBJFJEQQiVRREIIlUQRCSFUEkUkhFBJFJEQQiVRREIIlUQRCSFUEkUkhFBJFJEQQiVRREIIlUQRCSFUEkUkhFBJFJEQQiUxULNTnYf2DQ2Ou3rDKa2ajyRU5yHnKCJedR6bdwvCLDjIOYqIU9Zt3+zwoX4eco4i4lXS/h4q1MBBzlFEnPLQQ4XqPOQcRcQrB8fKoQYOco4i4lWyNO8WhFlwkHMUEaes25l3E8IMeMg5iohXDnqoUAMHOTdeRNYedXKlGcP/VPEf8cAvbqq0/pHHv7DS+nVIlhaHby5qWQ912JqNc50ZPnKen9gT8arT/h4q1MBBzlFEnDIHZ+1DdR5yjiLilYP7B0INHOQcRcQrByfcQg0c5BxFxKuk/T1UqIGDnHOLiKRnAq8GNqYPLQJXm9k9TTYs5HDQQ4UaOMh54qBEkt4LXAkI+F66CLhC0kXNNy+M1U2Gl7DyOMg5b0/kfODZZnbQxWpJnwLuAnaOWknSDmAHwJrVf8Hqw55QQ1PDQTrzv38gm7NWrWNh4eg5t2gFakHOefKKSA84HvjpwOPHpc+NZGa7gF1Q/WazMEbJ+wckbQU+C6wCLjOznQPPfxp4SfrrUcCTzeyY9LkusDd97mdmto0053nfbLZirYD7RN4FfFvSj4Gfp4/9NfA04IImGxZydLtTryJpFfA54OXA/cAeSVeb2d3LrzGzd2de/w5gc+YtDpjZptJtDtMrkfOsTSwiZvYtSc8ATuPgE6t7zKz9f91KVq6HOg2418z2AUi6kv5J87vHvP71wMWl2hfqsQL2RDCzHnDLDNoSpmBJqRq+kT/vUUJ/b+T0US+UdCJwMnB95uEjJN0KJMBOM/tKmUaE4krm3MRh61hxn4hXI064ZU90pnal56fK2A5cNbDHeaKZLUo6Bbhe0l4zu6/k+4ciSpxYnfVhaxQRr0ZsXNkT2mMsAk/J/H5C+tgo24G3D7z/YvrffZJ209/woog0qdzVmZketjY+edWCVGkJY3S7w0u+PcDTJZ0saQ39QnH14IvSGwzXA9/JPLZe0uHpzxuAMxi/UYa6lMt51GHrxlEvnHTYKukWSefmfVjsiThlS9PfdGRmiaQLgGvpHytfbmZ3SboEuNXMlgvKduBKM8tetj0VuFRSj37nszO7exyaMSrnth22RhHxquSlPzO7Brhm4LEPDPz+wRHr3Qw8t9SHhvJG5Ny2w9aYi9erTmd4CStPuZxnetgaeyJOlTmcCf54OGyNIuKVgzsZQw0cHLZGEXHKlqKIHAo85BxFxKuSdzIGZxzkXPrEqqS31NmQMB3rdIeWsPJ4yLnK1ZkPjXtC0o70ZpVbl5KHK3xEGMeS3tAya9mce70/zvzzDwVtyDnPxMMZSXeMewo4dtx62evYTzz6lBhnogG2NP+NKZtzjCfSjDbknCfvnMixwDnAbwceF3BzIy0KhXjYuEJ1HnLOKyJfB9aa2e2DT6R3soU5sSQ6/kOBh5zzBiU6f8Jzb6i/OaEoa/9YNaEGHnKOS7xOWdywekjwkHMUEae6DnqoUJ2HnKOIONXrxHcnDwUecm68iGjeAwv12ndzTh163Riw6VDgIefYE3Gq22n/xhWq85BzFBGnekn7d3NDdR5ybn8Lw0jdZGFoKULSVkk/knTvqPmUJZ0n6deSbk+Xt2aee7OkH6fLm2v8c8IYZXOepfa1KBSSJAtDS57MVAKvAJ4FvF7Ss0a89ItmtildLkvXfRL9EcFPpz+a+MWS1tf194TRyuQMs+0s4nDGqZIn3KadSiDrHOA6M9ufrnsdsBW4okxDQjFlci4y70zqi2Z2wcC6y53FFsCA29J1B7/68rjcsibpmZJeJmntwONbC/1FoRFJsmpoKaDoVAKvkXSHpKskLQ/4W3gaglCfkjk/3lmY2RKw3FkU8XhnkRaO5c5irIlFRNKFwFeBdwB3Sso25KMFGxUa0O1paMl+NT9dduS/05CvASeZ2fPob0Cfr7flYRqjci5gpp1F3uHM24Dnm9kjkk4CrpJ0kpl9lv43eUfKzotxxJoNrFn9xJyPCdNKusP1v46pBMzsN5lfLwM+lln3zIF1F9K5edGqdSwsHF2w9aGoUTnXNO/M14ArzOwxSf9Iv7N4aZk25hWRBTN7BMDMfiLpTPqF5EQmFJHsxrxu7VPb/zVEh5JeqXPij08lQL8obAcO+iKlpOPM7Jfpr9uAe9KfrwU+mjmZejb9DmY/xHgiTRmV8xw6i92T2pi3JT4g6fGJfdOC8ipgAzGR0Vx1ewtDSx4zS4DlqQTuAf5zeSoBScszv18o6S5JPwAuBM5L190PfJh+IdoDXLJcQEJzyuRMgXlnJB2X+XWwszg7nX9mPf3O4tpJH5a3J/Im4KDvEaYb4pskXZr3l4TmdKzcnYx5UwmY2fuA941Z93Lg8lIfHEopk3PBeWcuTDuOBNhPprOQtNxZQIHOIm88kfsnPPe/Bf+m0IBu3OJzSCib8yw7i7hPxKnO+FNSYQXxkHMUEae6DjauUJ2HnKOIONWZ9xALYSY85Nx4EXnCmiMrrf/HpT9VWr/3h9/kv8ghDxtXqM5DzrEn4lTS/m0r1MBDzlFEnPLQQ4XqPOQcRcSplTnoYxjkIecoIk4ttb+DCjXwkHMUEaccDL0ZauAh5ygiTjkYBDzUwEPOuUVE0mmAmdmedCi9rcAP09tqw5x05t2AMBMecp5YRCRdTH88zsPS4fBOB24ALpK02cw+Mma9x8c7OOao4zj68CfV2+rQikt/2ZxjPJFmtCHnPHl7Iq8FNgGHA78CTjCzhyV9AvguMLKIZMc7OOFJz4lxJhrQYf7/rNmcYzyRZrQh5zx5RSQxsy7wqKT7zOxhADM7IKnXfPPCOB5OuIXqPOScV0SWJB1lZo8Cz19+UNI6IIrIHHUd9FChOg855w1W8KK0gGBm2aKxGojJi+aogw0tRRSYj+Q9ku5OB/D9djoU5vJz3cw8JVcPrhvqVzbnWZpYRMzssTGPP2Rme5tpUigiwYaWPAUnr/o+sCUd7f0q/jz2JsCBzKRW2wiNK5MzzLaziOGxnCq5ceXOR2JmNyzvfQK30B+oN8yJh84iiohTJXdzp51T5Hzgm5nfj0jns7lF0rnTtzpMq2TOM+0sGr9jtdurdv616slpaWXWyVE9Uk3zkSy/1xvpT6X44szDJ5rZoqRTgOsl7TWz+8q8fyim6OHLgFGdxekTXj+ys6A/iPNOM/vKpA+L296dSkZcHKtjPhIASWcB7wdenD0vZmaL6X/3SdoNbAaiiDRoVM5t6yyiiDiVWKkeqsjkVZuBS4GtZvZg5vH1wKPpjGkbgDM4+Dg6NGBUzm3rLFbmvv4hIKE3tOQpOHnVx4G1wJcGzs6fCtyaTmp1A/3d3MFZ5kPNyuRMscmrljuLbYOdhaTD05+XO4uJOceeiFMlj5WLzEdy1pj1biZmPZy5MjkXnLwq21kA/Cy9EnMqcGl6R/oCBTqLKCJOJRY3DB8KyuY8y84iiohTnfjWwSHBQ85TnxOR9IUmGhKm07Xe0BJWHg85540nMnjLq4CXSDoGIG59nh8PPVSozkPOeYczJ9A/M3sZYPSLyBbgk5NWyl7HfuKRf8VRa9ZXb2k4SBt6pBiUqHltyDlP3uHMFuA2+teSf29mu+nfV3+jmd04biUz22VmW8xsSxSQZiTWG1pmLZtzFJBmtCHnPBP3RNKv/39a0pfS/z6Qt06YjY55mJEkVOUh50IFwczuB14n6ZXAw802KRTRdXCsHKrzkPNUexVm9g3gGw21JUwh6bW/hwrVecg5Dk2c8tBDheo85BxFxKmOgx4qVOch5ygiTiUOTriF6jzk3HgR+eXv7p44rpCkHWXHQqjrPSatnywNfYN6pp8/TtvuH0iWFhvNuentJHIurw1DAezIf0nj7+Fu/aSXDC0tN+9/4za0YUXmHIczTnnooUJ1HnKOIuKUh0t/oToPObehiFQ6zq3pPdyt76GHGjDvf+M2tGFF5iwrN1ZnmLN1a586FNzvH7nPwcytYRoecm7DnkgowcNubqjOQ85zvTqTN9VfzrqXS3pQ0p0lP/spkm5IpxK8S9I7S7zHEZK+J+kH6Xt8qGRbVkn6vqSvF12n2+sNLW3lOed5Zgw+cp5bESk41d8k/wZsrdCEBPhnM3sW8ALg7VN+PsBjwEvN7G+BTcBWSS8o0ZZ30h99vbBurzu0tNEKyHluGYOPnOe5J5I71d8kZvY/wP6yH25mvzSz/0t//gP9gCdNKTnqPczMHkl/XZ0uU51kknQC8Er6Az8V1lla1OAyzfoz5DrneWYMPnKeZxGZdl7Yxkg6if4EPd8tse4qSbcDDwLXmdm07/EZ4F/AwTetynGfc2Q8WRvuWJ0rSWuB/wLeZWZTj5ViZl0z20R/KMnTJD1nis9+FfCgmd027eeG6VTJOTKebJ5FpNBUf02StJr+hvUfZvblKu9lZr+jPzPcNMfvZwDbJP2E/m7+SyX9e5V2tNCKyTkyHsPM5rLQv7y8DzgZWAP8AHj2lO9xEnBnyc8X8AXgMxX+hr8Ejkl/PhK4CXhVyfc6E/j6vPKInCPjssvc9kRszLywRdeXdAXwHeBvJN0v6fwpm3AG8A/0e4bb0+XvpnyP44AbJN1Bf/7T68xsqkt4K90KyDkyzhF3rIYQKjnkT6yGEKqJIhJCqCSKSAihkigiIYRKooiEECqJIhJCqCSKSAihkigiIYRK/h8LruqkFWd2+AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Again, do the same for \"cross attention\""
      ],
      "metadata": {
        "id": "e-Te_yTmfhWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xattn_scores = xattn_q @ keys.mT\n",
        "xattn_scores_softmax = softmax(xattn_scores, dim=-1)\n",
        "\n",
        "show_multihead_attention(xattn_scores_softmax)"
      ],
      "metadata": {
        "id": "IE_QyISRZh_1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "76425e4b-0189-4386-e67e-9ae6eb62a3d0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_values = values[:,:,None] * attn_scores_softmax.mT[:,:,:,None]\n",
        "outputs = weighted_values.sum(dim=0)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "bJH6eJC7Zkoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc38614-3283-40d3-83ec-6043b00cb3f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[6.1692e-02, 5.8890e-02, 6.4591e-02, 7.3372e-02, 8.3964e-02,\n",
            "          4.3336e-02, 9.0969e-02],\n",
            "         [7.1396e-02, 6.8253e-02, 7.4816e-02, 8.2502e-02, 9.4964e-02,\n",
            "          5.1029e-02, 1.0356e-01],\n",
            "         [7.5121e-02, 7.1671e-02, 7.8621e-02, 8.9981e-02, 1.0283e-01,\n",
            "          5.2521e-02, 1.1123e-01],\n",
            "         [1.4713e-01, 1.4050e-01, 1.5409e-01, 1.7233e-01, 1.9777e-01,\n",
            "          1.0429e-01, 2.1508e-01],\n",
            "         [1.3409e-01, 1.2838e-01, 1.4061e-01, 1.5669e-01, 1.8008e-01,\n",
            "          9.5375e-02, 1.9566e-01]],\n",
            "\n",
            "        [[3.9639e-03, 3.3551e-03, 3.3338e-03, 3.7697e-03, 4.0610e-03,\n",
            "          3.1316e-03, 4.3843e-03],\n",
            "         [5.7699e-03, 4.9868e-03, 4.8967e-03, 5.4123e-03, 5.9365e-03,\n",
            "          4.6506e-03, 6.3407e-03],\n",
            "         [2.9436e-03, 2.2664e-03, 2.3823e-03, 2.9822e-03, 2.9600e-03,\n",
            "          2.1141e-03, 3.3435e-03],\n",
            "         [8.1046e-03, 7.0612e-03, 6.9069e-03, 7.5190e-03, 8.3356e-03,\n",
            "          6.6162e-03, 8.8864e-03],\n",
            "         [1.7253e-02, 1.3515e-02, 1.4072e-02, 1.7514e-02, 1.7430e-02,\n",
            "          1.2470e-02, 1.9482e-02]],\n",
            "\n",
            "        [[9.7280e+00, 1.0014e+01, 8.5844e+00, 9.2853e+00, 1.0371e+01,\n",
            "          9.5337e+00, 1.0435e+01],\n",
            "         [9.7093e+00, 9.9983e+00, 8.5673e+00, 9.2677e+00, 1.0350e+01,\n",
            "          9.5143e+00, 1.0414e+01],\n",
            "         [9.7145e+00, 1.0003e+01, 8.5738e+00, 9.2738e+00, 1.0358e+01,\n",
            "          9.5261e+00, 1.0423e+01],\n",
            "         [9.6091e+00, 9.9144e+00, 8.4833e+00, 9.1792e+00, 1.0250e+01,\n",
            "          9.4384e+00, 1.0315e+01],\n",
            "         [9.6100e+00, 9.9137e+00, 8.4839e+00, 9.1794e+00, 1.0250e+01,\n",
            "          9.4375e+00, 1.0315e+01]],\n",
            "\n",
            "        [[4.3284e-03, 4.4479e-03, 3.8978e-03, 3.5942e-03, 4.1436e-03,\n",
            "          4.5219e-03, 4.9508e-03],\n",
            "         [9.6330e-03, 9.6697e-03, 8.5372e-03, 7.9462e-03, 9.2212e-03,\n",
            "          9.9354e-03, 1.0894e-02],\n",
            "         [2.1399e-03, 2.2258e-03, 1.9611e-03, 1.7757e-03, 2.0434e-03,\n",
            "          2.2633e-03, 2.4829e-03],\n",
            "         [1.2394e-02, 1.3077e-02, 1.1572e-02, 1.0260e-02, 1.1807e-02,\n",
            "          1.3298e-02, 1.4583e-02],\n",
            "         [1.6715e-02, 1.7795e-02, 1.5122e-02, 1.4209e-02, 1.6087e-02,\n",
            "          1.7563e-02, 1.9142e-02]],\n",
            "\n",
            "        [[3.2365e-05, 3.0292e-05, 2.8378e-05, 3.0207e-05, 3.8148e-05,\n",
            "          2.8183e-05, 3.4175e-05],\n",
            "         [6.6140e-05, 6.4998e-05, 5.9773e-05, 6.2998e-05, 7.9779e-05,\n",
            "          6.2632e-05, 6.9210e-05],\n",
            "         [2.9829e-05, 2.2256e-05, 2.4358e-05, 2.6095e-05, 3.3194e-05,\n",
            "          2.2072e-05, 3.3846e-05],\n",
            "         [1.0826e-04, 8.8114e-05, 9.4925e-05, 9.8608e-05, 1.2647e-04,\n",
            "          1.0038e-04, 1.2322e-04],\n",
            "         [4.8744e-04, 4.3204e-04, 4.1722e-04, 4.4650e-04, 5.6370e-04,\n",
            "          3.9873e-04, 5.2268e-04]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert into expected shape for next layer\n",
        "\n",
        "A MLP is employed to \"fix the dimensions\". We require the output shape to match the original $x$ input shape. This can be achieved by creating a MLP weight matrix of the appropriate shape. \n",
        "\n",
        "It has one dimension given by the number of tokens times the internal embedding dimension, the other by the number of original embedding features.\n",
        "\n",
        "Notice that the MLP will require a 2D tensor input -- therefore the heads' outputs need to be flattened. The MLP can then mix the results from the different heads (per token).\n",
        "\n",
        "Consequentially, the MLP will have a rather large weight matrix."
      ],
      "metadata": {
        "id": "-L_UzVeSampm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create MLP weights\n",
        "The size of the MLP output needs to match the original $x$ input data matrix.\n",
        "This makes it possible to stack Attention blocks. Therefore, it has no free parameters."
      ],
      "metadata": {
        "id": "idGI0UqrhNmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_heads = outputs.flatten(1) # The heads are combined. The MLP will mix their results.\n",
        "\n",
        "mlp_weights = torch.rand([num_tokens*internal_embedding_dimensions, num_embedding_features])\n",
        "\n",
        "print(\"MLP size:\", mlp_weights.shape)\n",
        "result = combined_heads @ mlp_weights\n",
        "print(\"Resulting shape: \", result.shape)\n",
        "print(\"Resulting new input to next attention block:\", result)\n",
        "\n",
        "assert result.shape==x.shape"
      ],
      "metadata": {
        "id": "4wAF_IZsaZTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2965c5d9-b8d1-4f78-cb23-b51aa030f0bf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP size: torch.Size([35, 9])\n",
            "Resulting shape:  torch.Size([5, 9])\n",
            "Resulting new input to next attention block: tensor([[1.7576e+00, 1.8026e+00, 1.8227e+00, 2.2038e+00, 2.0527e+00, 1.8187e+00,\n",
            "         1.9433e+00, 1.9176e+00, 2.1799e+00],\n",
            "        [1.1240e-01, 1.1512e-01, 1.0927e-01, 1.4089e-01, 1.3365e-01, 1.1986e-01,\n",
            "         1.1951e-01, 1.3182e-01, 1.4726e-01],\n",
            "        [1.6497e+02, 1.6104e+02, 1.6925e+02, 1.9725e+02, 1.8334e+02, 1.6981e+02,\n",
            "         1.8587e+02, 1.6648e+02, 1.8826e+02],\n",
            "        [1.3980e-01, 1.4915e-01, 1.4843e-01, 1.7759e-01, 1.7238e-01, 1.5090e-01,\n",
            "         1.4915e-01, 1.5942e-01, 1.8797e-01],\n",
            "        [2.1522e-03, 2.2283e-03, 1.8580e-03, 2.7391e-03, 2.5784e-03, 2.3168e-03,\n",
            "         2.0982e-03, 2.7979e-03, 3.0942e-03]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "cd15cf184ab1178a055b183ecb11f28577274e2cc0c29065c013381fe9f37159"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}