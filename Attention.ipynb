{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtwenzel/image-video-understanding/blob/master/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J29FDh2JUNk_"
      },
      "source": [
        "# Self-Attention by Example\n",
        "\n",
        "Partially taken from https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a#8481"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HS7dexV7MphR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AoHRZd3SdJ0"
      },
      "source": [
        "## Create a tensor with input data.\n",
        "\n",
        "In a real setting, this tensor would be the result of some data encoding step (when considering the first input to the first attention layer), or the result of the previous attention layer.\n",
        "\n",
        "If for example your input is text, and your word embeddings have 512 dimensions, each row in the tensor $x$ would have 512 entries, and the tensor would have as many rows as your sentence has words.\n",
        "\n",
        "For images (here described along the lines of the ViT), the number of rows in $x$ is the number of tiles the images get subdivided into ($16 \\times 16$ in ViT). The length of each line is the length of the embedding vector after transforming each tile with the patch encoder. [See the ViT publication for details](https://arxiv.org/abs/2010.11929)\n",
        "\n",
        "Note that there is the embedding size of the original data, but also the internal encoding size that will be determined by the shape of the K, Q, and V matrices."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define data matrix {run:\"auto\"}\n",
        "#@markdown We randomly create data of a given size. Set the number of tokens and the encoding/embedding length here.\n",
        "num_tokens = 5 #@param {type:\"slider\", min:\"1\", max:\"16\"}\n",
        "num_embedding_features = 9 #@param {type:\"slider\", min:\"1\", max:\"32\"}\n",
        "\n",
        "x = torch.rand([num_tokens,num_embedding_features])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "h_FPHgn8fTEp",
        "outputId": "a116a7f4-eec1-4971-864c-0b58bc5ddb53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6517, 0.8906, 0.7827, 0.8115, 0.7145, 0.6297, 0.2204, 0.4647, 0.6275],\n",
              "        [0.8142, 0.8812, 0.5804, 0.3748, 0.8576, 0.4797, 0.4079, 0.4926, 0.6268],\n",
              "        [0.2218, 0.0530, 0.2225, 0.2021, 0.6635, 0.3007, 0.4895, 0.6165, 0.6814],\n",
              "        [0.1457, 0.9908, 0.5565, 0.6999, 0.9631, 0.7079, 0.5562, 0.4271, 0.3888],\n",
              "        [0.2261, 0.6747, 0.4376, 0.8431, 0.2675, 0.7606, 0.7579, 0.4795, 0.8052]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-E_fY_cdNJwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "d9ac7020-dae9-4085-d004-7fbc39965997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8430, 0.3511, 0.9490, 0.6537, 0.2568, 0.1407, 0.3621, 0.1959, 0.7121],\n",
              "        [0.5855, 0.7516, 0.8179, 0.9184, 0.2528, 0.0203, 0.7044, 0.7094, 0.3657]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#@title Define second data matrix for cross attention {run:\"auto\"}\n",
        "#@markdown To demonstrate cross attention with smaller attention matrix analogous to Perceiver or DETR, create a \"learned queries\" matrix $x_2$\n",
        "#@markdown For consistency, you can only adjust the number of tokens. The embedding dimension is kept from above.\n",
        "num_ca_tokens = 2 #@param {type:\"slider\", min:\"1\", max:\"10\"}\n",
        "\n",
        "x2 = torch.rand([num_ca_tokens, num_embedding_features])\n",
        "x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmV9pihNSumD"
      },
      "source": [
        "## Create a set of weight tensors. \n",
        "We are looking at single-head attention only for the moment. For multi-head attention, each weight matrix would be replicated (with independent weights) for each head. You will see this in the second half of the notebook.\n",
        "\n",
        "Each weight tensor has to have as many rows as the tokens have dimensions. Our input vectors have ```num_embedding_features``` dimensions. Let's create random weight matrices of the according size. You are free to select the other dimension, which will then be the internal embedding dimension.\n",
        "\n",
        "Observe how the size of these matrices does not depend on the number of tokens anymore.\n",
        "\n",
        "Note that this will result in a matrix output after the attention mechanism, instead of a single token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZSd8O7IANOK5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get K, Q, V {run:\"auto\"}\n",
        "\n",
        "internal_embedding_dimensions = 7 #@param {type:\"slider\", min:\"1\", max:\"32\"}\n",
        "\n",
        "w_key = torch.rand([num_embedding_features,internal_embedding_dimensions])\n",
        "w_query = torch.rand([num_embedding_features,internal_embedding_dimensions])\n",
        "w_value = torch.rand([num_embedding_features,internal_embedding_dimensions])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqLOpyeETMBN"
      },
      "source": [
        "## K, Q, and V\n",
        "\n",
        "The actual keys, querys and values are the result of the multiplication of input tensor with weight tensors.\n",
        "\n",
        "Their dimension is:\n",
        "* each row has as many entries as the weight tensors (three in our setup)\n",
        "* the number of rows equals the number of input tokens (five in our setup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXXZUtWWNSjM",
        "outputId": "24f3f2fe-f9a9-4327-e009-cd6ed1a96e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: tensor([[2.5897, 3.4990, 3.0024, 3.4828, 2.8932, 3.4983, 3.8478],\n",
            "        [2.2672, 3.0987, 3.0599, 3.4088, 2.8794, 3.2070, 3.4920],\n",
            "        [1.3091, 1.7048, 2.0314, 2.2647, 1.3877, 1.6308, 2.3068],\n",
            "        [2.2630, 3.4835, 2.7146, 3.2241, 2.4732, 3.0766, 3.4089],\n",
            "        [2.2300, 3.0621, 2.5522, 2.9022, 1.9396, 3.2127, 3.4243]])\n",
            "Queries: tensor([[4.2120, 2.1172, 2.6209, 3.3936, 1.6727, 4.0659, 3.0183],\n",
            "        [3.9962, 1.8665, 2.6113, 3.2344, 1.5313, 3.8870, 2.7400],\n",
            "        [2.1059, 1.2910, 1.7745, 2.0713, 0.9391, 2.1954, 1.3232],\n",
            "        [4.0678, 1.9888, 2.3130, 3.0192, 1.7567, 3.7109, 2.5710],\n",
            "        [3.4750, 1.8936, 1.9864, 3.1657, 1.7689, 3.4005, 2.4411]])\n",
            "Cross-attention Queries: tensor([[3.0445, 1.5360, 2.1254, 3.1568, 1.1841, 3.0001, 2.4078],\n",
            "        [3.3757, 1.8828, 1.9458, 3.3815, 1.4731, 3.4824, 2.5082]])\n",
            "Values: tensor([[2.5303, 2.1127, 3.8374, 3.7999, 2.9384, 3.0210, 3.0376],\n",
            "        [2.2076, 2.1000, 3.5818, 3.4944, 2.8775, 2.7790, 2.8775],\n",
            "        [1.4119, 1.4078, 2.1007, 2.1132, 1.7156, 1.3765, 1.9494],\n",
            "        [2.2105, 1.8831, 3.5905, 3.6241, 2.6707, 2.9108, 3.0839],\n",
            "        [2.3557, 1.9037, 3.5520, 3.6368, 2.4407, 2.7040, 2.6640]])\n"
          ]
        }
      ],
      "source": [
        "keys = x @ w_key\n",
        "querys = x @ w_query\n",
        "values = x @ w_value\n",
        "\n",
        "# This would be the cross attention with a potentially different number of tokens\n",
        "xattn_q = x2 @ w_query\n",
        "\n",
        "\n",
        "print(\"Keys:\",keys)\n",
        "print(\"Queries:\",querys)\n",
        "print(\"Cross-attention Queries:\",xattn_q)\n",
        "print(\"Values:\",values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNK5GEeBTfKC"
      },
      "source": [
        "## Softmax Attention\n",
        "\n",
        "The size of the square attention matrix equals the number of input tokens in both dimensions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "OoT9rEVZNVIN",
        "outputId": "dada428e-d4d2-4db8-ef46-a11f2e43ac5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9900, 0.0100, 0.0000, 0.0000, 0.0000],\n",
            "        [0.9800, 0.0100, 0.0000, 0.0000, 0.0000],\n",
            "        [0.8900, 0.0800, 0.0000, 0.0200, 0.0000],\n",
            "        [0.9800, 0.0100, 0.0000, 0.0000, 0.0000],\n",
            "        [0.9800, 0.0200, 0.0000, 0.0000, 0.0000]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc90b90fd90>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "attn_scores = querys @ keys.T\n",
        "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
        "\n",
        "# For readability, round the scores to a definable number of decimal place.\n",
        "decimal_places = 2\n",
        "attn_scores_softmax = (attn_scores_softmax * 10**decimal_places).round() / (10**decimal_places)\n",
        "print(attn_scores_softmax)\n",
        "\n",
        "# Plot self attention matrix\n",
        "t = attn_scores_softmax.numpy()\n",
        "sns.heatmap(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do the same for \"cross attention\""
      ],
      "metadata": {
        "id": "purX4lQ8XkJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = xattn_q @ keys.T\n",
        "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
        "\n",
        "# For readability, round the scores to a definable number of decimal place.\n",
        "decimal_places = 2\n",
        "attn_scores_softmax = (attn_scores_softmax * 10**decimal_places).round() / (10**decimal_places)\n",
        "print(attn_scores_softmax)\n",
        "\n",
        "# Plot self attention matrix\n",
        "t = attn_scores_softmax.numpy()\n",
        "sns.heatmap(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "hM8FSWsWXc_y",
        "outputId": "ffb5a1a5-0580-4ed2-ca69-79b27eca7f95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9600, 0.0300, 0.0000, 0.0000, 0.0000],\n",
            "        [0.9800, 0.0200, 0.0000, 0.0000, 0.0000]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc90b90f040>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAODUlEQVR4nO3db6xk9V3H8feHBcSUWqNorbtbS9NFXVGLIbSGB21a0KUa9oHGQFNjDfE+EUNt/UOjIRafWI3oE0xcKVZrC1Y05qauYtNCmmihuwpSdxHdrFp2NcFWWjW2Xe6drw/uUIeb3Zm5e+f+ZubH+7U5ycyZc3/zOyH72S/f8zvnpqqQJLVxwbwnIEkvJoauJDVk6EpSQ4auJDVk6EpSQxfu9BecOfXp7pZHfN0VN857CjviS2tn5j0FvcitnTmd7Y7x3GdPTp05F1326m1/31ZZ6UpSQzte6UpSU4P1ec9gLENXUl/W1+Y9g7EMXUldqRrMewpjGbqS+jIwdCWpHStdSWrIC2mS1JCVriS1U65ekKSGvJAmSQ3ZXpCkhryQJkkNWelKUkNeSJOkhryQJkntVNnTlaR27OlKUkO2FySpIStdSWpo/bl5z2AsQ1dSX2wvSFJDthckqSErXUlqyNCVpHbKC2mS1JA9XUlqyPaCJDVkpStJDVnpSlJDVrqS1NCaDzGXpHasdCWpIXu6ktSQla4kNWSlK0kNLXile8G8JyBJM7W2Nv02QZIDSZ5KciLJ7Wf5/JVJHkryWJInkrxl0piGrqS+VE2/jZFkF3A3cAOwH7g5yf5Nh/0i8OGqugq4CfitSdOzvSCpL7Pr6V4DnKiqkwBJ7gcOAsdHjinga4avXwb826RBDV1JfdlC6CZZAVZGdh2qqkPD17uBp0c+OwW8btMQvwT8ZZKfAl4CXDfpOw1dSX3ZwoW0YcAemnjgud0MvL+qfj3J9wIfSHJl1bknYehK6sv6+qxGOg3sHXm/Z7hv1C3AAYCq+mSSS4DLgGfONagX0iT1ZTCYfhvvCLAvyeVJLmbjQtnqpmM+A7wZIMm3A5cA/zFuUCtdSX2Z0YW0qlpLcivwILALuLeqjiW5EzhaVavAu4DfSfLTbFxUe3vV+GURhq6kvszw5oiqOgwc3rTvjpHXx4FrtzKmoSupKzUYv/523gxdSX3x2QuS1NDsVi/sCENXUl+sdCWpIUNXkhqa8CCbeTN0JfXFSleSGlr2JWNJvo2Nx5ntHu46DaxW1ZM7OTFJOi8Lvnph7LMXkvw8cD8Q4FPDLcB9Z3uK+sjPrSQ5muToPR98YJbzlaSxajCYepuHSZXuLcB3VNVzozuT3AUcA37lbD80+ri0M6c+vdi1vqS+LHh7YdJTxgbAN59l/yuGn0nSYqnB9NscTKp03wF8LMk/8f9PUH8l8Brg1p2cmCSdlwWvdMeGblX9RZIr2PhdQaMX0o5U1WJ3qyW9OK0tdjRNXL0w/LUTjzSYiyRt35zaBtNyna6kvixze0GSls28loJNy9CV1BcrXUlqyNCVpIYW/DZgQ1dSV/wdaZLUkqErSQ25ekGSGrLSlaSGDF1JaqfWbS9IUjtWupLUjkvGJKklQ1eSGlrslq6hK6kvtbbYqWvoSurLYmeuoSupL15Ik6SWrHQlqR0rXUlqacEr3QvmPQFJmqVam36bJMmBJE8lOZHk9nMc8yNJjic5luRDk8a00pXUlVn9BvYku4C7geuBU8CRJKtVdXzkmH3Au4Frq+rZJN84aVwrXUl9GWxhG+8a4ERVnayqM8D9wMFNx/wEcHdVPQtQVc9MGtTQldSVGky/JVlJcnRkWxkZajfw9Mj7U8N9o64ArkjyV0keSXJg0vxsL0jqylbaC1V1CDi0ja+7ENgHvBHYA3wiyXdW1efH/YAkdaPWM6uhTgN7R97vGe4bdQp4tKqeA/45yT+yEcJHzjWo7QVJXdlKe2GCI8C+JJcnuRi4CVjddMyfslHlkuQyNtoNJ8cNaqUrqSs1mE2lW1VrSW4FHgR2AfdW1bEkdwJHq2p1+Nn3JTkOrAM/W1WfGzeuoSupK7NaMgZQVYeBw5v23THyuoB3DrepGLqSulI1s57ujjB0JXVllpXuTjB0JXVlMLvVCzvC0JXUlVldSNsphq6krhi6ktRQLfbjdA1dSX2x0pWkhlwyJkkNrbt6QZLasdKVpIbs6UpSQ65ekKSGrHQlqaH1wWI/JtzQldQV2wuS1NDA1QuS1I5LxiSpoRd9eyGXvGSnv6K59UV/SrL0ImZ7QZIacvWCJDW04N0FQ1dSX2wvSFJDrl6QpIYW/TK3oSupK4WVriQ1s2Z7QZLasdKVpIbs6UpSQ1a6ktSQla4kNbRupStJ7Sz4b+sxdCX1ZWClK0nt+MAbSWpo0S+kLfaDJyVpiwbJ1NskSQ4keSrJiSS3jznuh5JUkqsnjWmlK6kr6zMaJ8ku4G7geuAUcCTJalUd33TcS4HbgEenGddKV1JXBpl+m+Aa4ERVnayqM8D9wMGzHPfLwHuBL00zP0NXUlcGZOotyUqSoyPbyshQu4GnR96fGu77iiTfA+ytqj+bdn62FyR1ZSurF6rqEHDofL4nyQXAXcDbt/Jzhq6krszw5ojTwN6R93uG+573UuBK4OFsXJT7JmA1yY1VdfRcgxq6kroywyVjR4B9SS5nI2xvAt76/IdV9QXgsuffJ3kY+JlxgQuGrqTOrM+o0q2qtSS3Ag8Cu4B7q+pYkjuBo1W1ej7jGrqSujLLmyOq6jBweNO+O85x7BunGdPQldSVRb8jzdCV1JUF/xVphq6kvljpSlJDs7oNeKcYupK64kPMJakh2wuS1JChK0kN+ZsjJKkhe7qS1JCrFySpocGCNxgMXUld8UKaJDW02HWuoSupM1a6ktTQWha71jV0JXVlsSPX0JXUGdsLktSQS8YkqaHFjlxDV1JnbC9IUkPrC17rGrqSumKlK0kNlZWuJLVjpStJDblkTJIaWuzINXQldWZtwWPX0JXUlUW/kHbB+f5gkh8f89lKkqNJjt7z+/ed71dI0pYNtrDNw3Yq3fcAv3u2D6rqEHAI4LnPnlzsf3YkdWXRK92xoZvkiXN9BLx89tORpO1Z9iVjLwe+H3h20/4Af70jM5KkbVivJa50gY8Al1bV45s/SPLwjsxIkrZhqdfpVtUtYz576+ynI0nbs9Q9XUlaNove0z3vJWOStIgG1NTbJEkOJHkqyYkkt5/l83cmOZ7kiSQfS/Itk8Y0dCV1pbbwZ5wku4C7gRuA/cDNSfZvOuwx4Oqq+i7gAeBXJ83P0JXUlfWqqbcJrgFOVNXJqjoD3A8cHD2gqh6qqv8dvn0E2DNpUENXUle20l4YvXt2uK2MDLUbeHrk/anhvnO5BfjzSfPzQpqkrmzlQtro3bPbkeRtwNXAGyYda+hK6soMl4ydBvaOvN8z3PcCSa4DfgF4Q1V9edKghq6krszw5ogjwL4kl7MRtjcBL7g/IclVwG8DB6rqmWkGNXQldaVmdBtwVa0luRV4ENgF3FtVx5LcCRytqlXg14BLgT9KAvCZqrpx3LiGrqSuzPJXsFfVYeDwpn13jLy+bqtjGrqSurLUz16QpGUzq/bCTjF0JXXFSleSGvIpY5LU0LI/xFySlortBUlqyNCVpIZcvSBJDVnpSlJDrl6QpIbWa7F/S5qhK6kr9nQlqSF7upLUkD1dSWpoYHtBktqx0pWkhly9IEkN2V6QpIZsL0hSQ1a6ktSQla4kNbRe6/OewliGrqSueBuwJDXkbcCS1JCVriQ15OoFSWrI1QuS1JC3AUtSQ/Z0Jakhe7qS1JCVriQ15DpdSWrISleSGnL1giQ15IU0SWpo0dsLF8x7ApI0S7WFP5MkOZDkqSQnktx+ls+/KskfDj9/NMmrJo1p6ErqSlVNvY2TZBdwN3ADsB+4Ocn+TYfdAjxbVa8BfgN476T5GbqSujKomnqb4BrgRFWdrKozwP3AwU3HHAR+b/j6AeDNSTJu0B3v6V502avHTmCWkqxU1aGd/p4vfvFfd/orXqDVebXU4zlBn+e1bOe0dub01JmTZAVYGdl1aORcdwNPj3x2CnjdpiG+ckxVrSX5AvD1wGfP9Z29Vborkw9ZSj2eV4/nBH2eV4/nBEBVHaqqq0e2Hf/HpbfQlaRZOQ3sHXm/Z7jvrMckuRB4GfC5cYMaupJ0dkeAfUkuT3IxcBOwuumYVeDHhq9/GPh4TbhC19s63aXpO21Rj+fV4zlBn+fV4zlNNOzR3go8COwC7q2qY0nuBI5W1SrwPuADSU4A/8lGMI+VRV9ILEk9sb0gSQ0ZupLUUBehO+lWvWWU5N4kzyT5+3nPZZaS7E3yUJLjSY4luW3ec9quJJck+VSSvxue03vmPadZSrIryWNJPjLvufRg6UN3ylv1ltH7gQPznsQOWAPeVVX7gdcDP9nBf68vA2+qqu8GXgscSPL6Oc9plm4Dnpz3JHqx9KHLdLfqLZ2q+gQbV0O7UlX/XlV/O3z932z8Zd4931ltT234n+Hbi4ZbF1eok+wBfgC4Z95z6UUPoXu2W/WW+i/xi8XwiUxXAY/OdybbN/xf8MeBZ4CPVtXSn9PQbwI/Byz2k8GXSA+hqyWU5FLgj4F3VNV/zXs+21VV61X1WjbuWromyZXzntN2JflB4Jmq+pt5z6UnPYTuNLfqaYEkuYiNwP1gVf3JvOczS1X1eeAh+ujHXwvcmORf2GjbvSnJH8x3Ssuvh9Cd5lY9LYjhY+/eBzxZVXfNez6zkOQbknzt8PVXA9cD/zDfWW1fVb27qvZU1avY+Hv18ap625yntfSWPnSrag14/la9J4EPV9Wx+c5q+5LcB3wS+NYkp5LcMu85zci1wI+yUTU9PtzeMu9JbdMrgIeSPMFGEfDRqnJ5lc7K24AlqaGlr3QlaZkYupLUkKErSQ0ZupLUkKErSQ0ZupLUkKErSQ39H9jgCSzHWz80AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUABFsoQTyAV"
      },
      "source": [
        "## Multiply softmax attention with V to obtain the result\n",
        "\n",
        "In a transformer, dense layers would follow that can \n",
        "* reduce a multi-head attention result\n",
        "* enforce correct dimensionality to use output in next input.\n",
        "\n",
        "We will see this after the following experiment with multi-head attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKW44_0GNjAU",
        "outputId": "c3bd07ca-a846-413b-8a58-11cf416846ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.4954, 2.0912, 3.7913, 3.7528, 2.9072, 2.9835, 3.0024],\n",
            "        [2.5239, 2.1124, 3.8323, 3.7938, 2.9372, 3.0162, 3.0344]])\n"
          ]
        }
      ],
      "source": [
        "weighted_values = values[:,None] * attn_scores_softmax.T[:,:,None]\n",
        "outputs = weighted_values.sum(dim=0)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention"
      ],
      "metadata": {
        "id": "fbvKL9qlY5rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C2rOtYHLY8fW"
      },
      "outputs": [],
      "source": [
        "w_key = [[\n",
        "  [0, 0, 1],\n",
        "  [1, 1, 0],\n",
        "  [0, 1, 0],\n",
        "  [1, 1, 0]\n",
        "],\n",
        "[\n",
        "  [0, .3, .1],\n",
        "  [1, 1, .2],\n",
        "  [0, .1, 0],\n",
        "  [.8, .1, 0]\n",
        "]]\n",
        "w_query = [[\n",
        "  [1, .2, 1],\n",
        "  [1, 0, .4],\n",
        "  [.5, 0, 1],\n",
        "  [0, .8, 1]\n",
        "],\n",
        "[\n",
        "  [1, .2, 1],\n",
        "  [1, 0, .4],\n",
        "  [.5, 0, 1],\n",
        "  [0, .8, 1]\n",
        "]]\n",
        "w_value = [[\n",
        "  [0, 2, 0],\n",
        "  [0, 3, 0],\n",
        "  [1, 0, 3],\n",
        "  [1, 1, 0]\n",
        "],\n",
        "[\n",
        "  [0, 2, 0],\n",
        "  [0, 3, 0],\n",
        "  [1, 0, 3],\n",
        "  [1, 1, 0]\n",
        "]]\n",
        "w_key = torch.tensor(w_key, dtype=torch.float32)\n",
        "w_query = torch.tensor(w_query, dtype=torch.float32)\n",
        "w_value = torch.tensor(w_value, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "e4a3e52c-2069-4714-d743-4cdef83f2a1c",
        "id": "cNyAD9WWZYfh"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f21cc51f9f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mquerys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxattn_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6x4 and 9x5)"
          ]
        }
      ],
      "source": [
        "keys = x @ w_key\n",
        "querys = x @ w_query\n",
        "\n",
        "xattn_q = x2 @ w_query\n",
        "\n",
        "values = x @ w_value\n",
        "\n",
        "print(keys)\n",
        "print(querys)\n",
        "print(xattn_q)\n",
        "print(values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = querys @ keys.mT \n",
        "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
        "\n",
        "# For readability, round the scores to a definable number of decimal place.\n",
        "decimal_places = 2\n",
        "attn_scores_softmax = (attn_scores_softmax * 10**decimal_places).round() / (10**decimal_places)\n",
        "print(attn_scores_softmax)\n",
        "\n",
        "# Plot self attention matrix\n",
        "t = attn_scores_softmax.numpy()\n",
        "sns.heatmap(t[0])\n",
        "#sns.heatmap(t[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "bKW_rBOtZe4Y",
        "outputId": "3c6ff058-6bd0-441c-f299-64d2794954c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0100, 0.6800, 0.0100, 0.0000, 0.3100],\n",
            "         [0.0000, 0.9800, 0.0000, 0.0000, 0.0200],\n",
            "         [0.0000, 0.9300, 0.0000, 0.0000, 0.0700],\n",
            "         [0.0000, 0.7200, 0.0000, 0.0000, 0.2700],\n",
            "         [0.0000, 0.8800, 0.0000, 0.0000, 0.1200]],\n",
            "\n",
            "        [[0.0000, 0.9900, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.9900, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f26c9abf4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = xattn_q @ keys.mT\n",
        "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
        "\n",
        "# For readability, round the scores to a definable number of decimal place.\n",
        "decimal_places = 2\n",
        "attn_scores_softmax = (attn_scores_softmax * 10**decimal_places).round() / (10**decimal_places)\n",
        "print(attn_scores_softmax)\n",
        "\n",
        "# Plot self attention matrix\n",
        "t = attn_scores_softmax.numpy()\n",
        "sns.heatmap(t[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "IE_QyISRZh_1",
        "outputId": "76ac01ad-405c-48f7-9e0d-eadce453ee94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0100, 0.6800, 0.0100, 0.0000, 0.3100],\n",
            "         [0.0000, 0.9800, 0.0000, 0.0000, 0.0200]],\n",
            "\n",
            "        [[0.0000, 0.9900, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f26c9ab41f0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_values = values[:,:,None] * attn_scores_softmax.mT[:,:,:,None]\n",
        "outputs = weighted_values.sum(dim=0)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJH6eJC7Zkoj",
        "outputId": "7f6f03e8-5f47-4634-fca2-2b37320de041"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0300,  0.0400,  0.0300],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 3.3400, 16.7000,  0.0000],\n",
            "         [ 3.9600, 19.8000,  0.0000]],\n",
            "\n",
            "        [[ 0.0200,  0.0600,  0.0300],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.9300,  1.8600,  0.9300],\n",
            "         [ 0.0600,  0.1200,  0.0600]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert into expected shape for next layer\n",
        "\n",
        "A MLP is employed to \"fix the dimensions\". We require"
      ],
      "metadata": {
        "id": "-L_UzVeSampm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_weights = torch.tensor([[0.6905, 0.9040, 0.8092, 0.0374],\n",
        "        [0.7709, 0.1924, 0.0805, 0.0564],\n",
        "        [0.1738, 0.0420, 0.3183, 0.0574],\n",
        "        [0.7654, 0.7641, 0.9147, 0.6214],\n",
        "        [0.9611, 0.7082, 0.8878, 0.8399],\n",
        "        [0.5197, 0.7513, 0.5941, 0.5541]])\n",
        "\n",
        "result = combined_heads @ mlp_weights\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "4wAF_IZsaZTS",
        "outputId": "16c60297-461e-487c-cfbe-d96c00df25d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-51f0dd73d09c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         [0.5197, 0.7513, 0.5941, 0.5541]])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_heads\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mmlp_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'combined_heads' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJIxYz5uhg9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "cd15cf184ab1178a055b183ecb11f28577274e2cc0c29065c013381fe9f37159"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}